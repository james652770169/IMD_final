import streamlit as st
st.set_page_config(page_title="國立虎尾科技大學機械設計工程系", layout="wide")


st.header("4.1結論")

st.markdown(' 題目三在本次實作中，YOLO 三類蔬果偵測本身可正常運作，但在延伸到 SAM 分割與 Object Counting 時未能完成主要功能。SAM 分割部分的問題集中在推論延遲與影像前處理造成的座標對齊不一致：影像串流在 resize/letterbox 後若未同步進行 bbox 座標映射，會導致「YOLO 框正確但 SAM 遮罩偏移或僅分割到局部」，加上 SAM 計算量較大使即時性不足，分割結果無法穩定輸出。Object Counting 則因多物件靠近或遮擋時框選容易跳動、漏檢或重複框選，缺少跨影格追蹤與去重平滑機制時，計數結果容易不穩定而難以呈現可重現的統計輸出。總體而言，題目三未達成之處並非 YOLO 辨識失效，而是延伸功能在效能、同步與穩定性整合上未能建立可靠流程。。')

st.header("4.2心得")
st.write("""
"這份期末作業讓我最有感的是：把「訓練模型」接到「ROS 機器人」上，才會發現難點多半不在模型本身，而是在整套系統的整合與穩定度。

在自主導航與避障的部分，我學到的是 ROS 架構的基本流程（SLAM 建圖、存圖、載圖、AMCL 定位、move_base 規劃與 costmap），也實際遇到像是 costmap 清除、DWA 找不到路、recovery 失效等狀況，才知道參數與感測器品質會直接影響「能不能走」。另外跨裝置（VM、PC、樹莓派）連線時，ROS_MASTER_URI、ROS_IP/ROS_HOSTNAME 設定不一致就會整個收不到 topic，這種問題以前看教學很難體會，但實作一次就記得很深。

在 AI 影像辨識/YOLO 的部分，我原本以為「訓練好模型＝完成」，但真正要做到可展示，需要把相機影像串流、推論、標籤對應、再轉成 /cmd_vel 控制命令全部串起來，還要處理延遲、抖動、誤判與安全限制（速度上限、防撞、冷卻時間等）。尤其是延伸到 SAM 分割與 Object Counting 時，才發現算力與座標對齊、跨影格穩定性（追蹤/去重）是關鍵，沒有把管線做穩，即使單一步驟能跑也很難做出可靠結果。

總結來說，這份作業讓我從「會跑範例」進步到「理解整合時會卡在哪」，也更清楚期末展示要成功，除了模型準確率，系統工程（網路、topic、參數、效能、穩定性與安全策略）**才是完成度的核心。
""")